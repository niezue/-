{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNnpp61T18HVOXGXKQ8yCAF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niezue/-/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ah3H9wsoATS",
        "outputId": "354e48d6-79d8-48b0-8488-b9197348997a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls /content/drive/MyDrive/\n",
        "# !unzip /content/drive/MyDrive/train_mask.csv.zip -d /content/drive/MyDrive\n",
        "# !unzip /content/drive/MyDrive/test_a.zip -d /content/drive/MyDrive\n",
        "# !unzip /content/drive/MyDrive/train.zip -d /content/drive/MyDrive\n",
        "\n",
        "# !pip install segmentation_models_pytorch\n",
        "# !pip install ttach"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f82Rqc4LolKE",
        "outputId": "1763e4ff-8a6a-4ec1-c05c-f3f38c1c3bcf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/test_a.zip\n",
            "replace /content/drive/MyDrive/test_a/CODGOQQLFN.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pathlib, sys, os, random, time\n",
        "import numba, cv2, gc\n",
        "from tqdm import tqdm_notebook\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import KFold\n",
        "import albumentations as A\n",
        "import segmentation_models_pytorch as smp\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as D\n",
        "from torchvision import transforms as T\n",
        "import ttach as tta\n",
        "\n",
        "\n",
        "\n",
        "EPOCHES = 40\n",
        "BATCH_SIZE = 8\n",
        "IMAGE_SIZE = 256\n",
        "DEVICE = 'cuda'\n",
        "\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(filename='/content/drive/MyDrive/log_unet_sh_fold_4_s.log',\n",
        "                    format='%(asctime)s - %(name)s - %(levelname)s -%(module)s:  %(message)s',\n",
        "                    datefmt='%Y-%m-%d %H:%M:%S ',\n",
        "                    level=logging.INFO)\n",
        "\n",
        "\n",
        "def set_seeds(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "set_seeds()\n",
        "\n",
        "#\n",
        "def rle_encode(im):\n",
        "    '''\n",
        "    im: numpy array, 1 - mask, 0 - background\n",
        "    Returns run length as string formated\n",
        "    '''\n",
        "    pixels = im.flatten(order='F')\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)\n",
        "\n",
        "\n",
        "def rle_decode(mask_rle, shape=(512, 512)):\n",
        "    '''\n",
        "    mask_rle: run-length as string formated (start length)\n",
        "    shape: (height,width) of array to return\n",
        "    Returns numpy array, 1 - mask, 0 - background\n",
        "\n",
        "    '''\n",
        "    s = mask_rle.split()\n",
        "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
        "    starts -= 1\n",
        "    ends = starts + lengths\n",
        "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
        "    for lo, hi in zip(starts, ends):\n",
        "        img[lo:hi] = 1\n",
        "    return img.reshape(shape, order='F')\n",
        "\n",
        "\n",
        "train_trfm = A.Compose([\n",
        "    A.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.RandomRotate90(),\n",
        "    A.OneOf([\n",
        "        A.RandomContrast(),\n",
        "        A.RandomGamma(),\n",
        "        A.RandomBrightness(),\n",
        "        A.ColorJitter(brightness=0.07, contrast=0.07,\n",
        "                      saturation=0.1, hue=0.1, always_apply=False, p=0.3),\n",
        "    ], p=0.3),\n",
        "\n",
        "\n",
        "])\n",
        "\n",
        "\n",
        "class TianChiDataset(D.Dataset):\n",
        "    def __init__(self, paths, rles, transform, test_mode=False):\n",
        "        self.paths = paths\n",
        "        self.rles = rles\n",
        "        self.transform = transform\n",
        "        self.test_mode = test_mode\n",
        "\n",
        "        self.len = len(paths)\n",
        "        self.as_tensor = T.Compose([\n",
        "            T.ToPILImage(),\n",
        "            T.Resize(IMAGE_SIZE),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize([0.625, 0.448, 0.688],\n",
        "                        [0.131, 0.177, 0.101]),\n",
        "        ])\n",
        "\n",
        "    # get data operation\n",
        "    def __getitem__(self, index):\n",
        "        img = cv2.imread(self.paths[index])\n",
        "        if not self.test_mode:\n",
        "            mask = rle_decode(self.rles[index])\n",
        "            augments = self.transform(image=img, mask=mask)\n",
        "            return self.as_tensor(augments['image']), augments['mask'][None]\n",
        "        else:\n",
        "            return self.as_tensor(img)\n",
        "\n",
        "    # def __getitem__(self, index):\n",
        "    #     img = cv2.imread(self.paths[index])\n",
        "    #     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # 转换颜色通道\n",
        "    #     img = np.array(img)  # 将图像转换为 NumPy 数组\n",
        "    #     if not self.test_mode:\n",
        "    #         mask = rle_decode(self.rles[index])\n",
        "    #         augments = self.transform(image=img, mask=mask)\n",
        "    #         return self.as_tensor(augments['image']), augments['mask'][None]\n",
        "    #     else:\n",
        "    #         return self.as_tensor(img)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Total number of samples in the dataset\n",
        "        \"\"\"\n",
        "        return self.len\n",
        "\n",
        "train_mask = pd.read_csv(r\"/content/drive/MyDrive/train_mask.csv\", sep='\\t', names=['name', 'mask'])\n",
        "train_mask['name'] = train_mask['name'].apply(lambda x: r'/content/drive/MyDrive/train/' + x)\n",
        "\n",
        "dataset = TianChiDataset(\n",
        "    train_mask['name'].values,\n",
        "    train_mask['mask'].fillna('').values,\n",
        "    train_trfm, False\n",
        ")\n",
        "\n",
        "@torch.no_grad()\n",
        "def validation(model, loader, loss_fn):\n",
        "    losses = []\n",
        "    model.eval()\n",
        "    for image, target in loader:\n",
        "        image, target = image.to(DEVICE), target.float().to(DEVICE)\n",
        "        output = model(image)\n",
        "        loss = loss_fn(output, target)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    return np.array(losses).mean()\n",
        "\n",
        "\n",
        "class SoftDiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=1., dims=(-2, -1)):\n",
        "        super(SoftDiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "        self.dims = dims\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        tp = (x * y).sum(self.dims)\n",
        "        fp = (x * (1 - y)).sum(self.dims)\n",
        "        fn = ((1 - x) * y).sum(self.dims)\n",
        "\n",
        "        dc = (2 * tp + self.smooth) / (2 * tp + fp + fn + self.smooth)\n",
        "        dc = dc.mean()\n",
        "        return 1 - dc\n",
        "\n",
        "\n",
        "bce_fn = nn.BCEWithLogitsLoss()  # nn.NLLLoss()\n",
        "dice_fn = SoftDiceLoss()\n",
        "\n",
        "\n",
        "def loss_fn(y_pred, y_true, ratio=0.8, hard=False):\n",
        "    bce = bce_fn(y_pred, y_true)\n",
        "    if hard:\n",
        "        dice = dice_fn((y_pred.sigmoid()).float() > 0.5, y_true)\n",
        "    else:\n",
        "        dice = dice_fn(y_pred.sigmoid(), y_true)\n",
        "    return ratio * bce + (1 - ratio) * dice\n",
        "header = r'''\n",
        "        Train | Valid\n",
        "Epoch |  Loss |  Loss | Time, m\n",
        "'''\n",
        "#          Epoch         metrics            time\n",
        "raw_line = '{:6d}' + '\\u2502{:7.4f}' * 2 + '\\u2502{:6.2f}'\n",
        "print(header)\n",
        "\n",
        "skf = KFold(n_splits=5)\n",
        "idx = np.array(range(len(dataset)))\n",
        "for fold_idx, (train_idx, valid_idx) in enumerate(skf.split(idx, idx)):\n",
        "    # select folder\n",
        "    if fold_idx != 4:\n",
        "        continue\n",
        "    print(\"fold_idx:\",fold_idx)\n",
        "    train_ds = D.Subset(dataset, train_idx)\n",
        "    valid_ds = D.Subset(dataset, valid_idx)\n",
        "\n",
        "    # define training and validation data loaders\n",
        "    loader = D.DataLoader(\n",
        "        train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "    vloader = D.DataLoader(\n",
        "        valid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "    model = smp.UnetPlusPlus(\n",
        "        encoder_name=\"efficientnet-b4\",  # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
        "        encoder_weights='imagenet',  # use `imagenet` pretreined weights for encoder initialization\n",
        "        in_channels=3,  # model input channels (1 for grayscale images, 3 for RGB, etc.)\n",
        "        classes=1,  # model output channels (number of classes in your dataset)\n",
        "    )\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-3)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=40, T_mult=1, eta_min=1e-6,last_epoch=-1,verbose=True)\n",
        "    model.to(DEVICE)\n",
        "    best_loss = 10\n",
        "    for epoch in range(1, EPOCHES + 1):\n",
        "        losses = []\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        for image, target in tqdm(loader):\n",
        "            image, target = image.to(DEVICE), target.float().to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(image)\n",
        "            loss = loss_fn(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            losses.append(loss.item())\n",
        "        print(\"train_loss:\", loss)\n",
        "        model.eval()\n",
        "        vloss = validation(model, vloader, loss_fn)\n",
        "        scheduler.step(vloss)\n",
        "        logging.info(raw_line.format(epoch, np.array(losses).mean(), vloss,\n",
        "                                   (time.time() - start_time) / 60 ** 1))\n",
        "        losses = []\n",
        "        if vloss < best_loss:\n",
        "            best_loss = vloss\n",
        "            torch.save(model.state_dict(), '/content/drive/MyDrive/fold{}_UnetP_model_new4_s.pth'.format(fold_idx))\n",
        "            print(\"best loss is{}\".format(best_loss))\n",
        "\n",
        "\n",
        "\n",
        "trfm = T.Compose([\n",
        "    T.ToPILImage(),\n",
        "    T.Resize(IMAGE_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.625, 0.448, 0.688],\n",
        "                [0.131, 0.177, 0.101]),\n",
        "])\n",
        "\n",
        "subm = []\n",
        "\n",
        "model = smp.UnetPlusPlus(\n",
        "    encoder_name=\"efficientnet-b4\",  # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
        "    encoder_weights='imagenet',  # use `imagenet` pretreined weights for encoder initialization\n",
        "    in_channels=3,  # model input channels (1 for grayscale images, 3 for RGB, etc.)\n",
        "    classes=1,  # model output channels (number of classes in your dataset)\n",
        ")\n",
        "\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/fold4_UnetPP_model_new4_s.pth\"))\n",
        "model.eval()\n",
        "model = tta.SegmentationTTAWrapper(model, tta.aliases.d4_transform(), merge_mode='mean')\n",
        "model = model.to(DEVICE)\n",
        "test_mask = pd.read_csv(r'/content/drive/MyDrive/test_a_samplesubmit.csv', sep='\\t', names=['name', 'mask'])\n",
        "test_mask['name'] = test_mask['name'].apply(lambda x: r'/content/drive/MyDrive/test_a/' + x)\n",
        "def rle_encode(im):\n",
        "    '''\n",
        "    im: numpy array, 1 - mask, 0 - background\n",
        "    Returns run length as string formated\n",
        "    '''\n",
        "    pixels = im.flatten(order='F')\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)\n",
        "def rle_decode(mask_rle, shape=(512, 512)):\n",
        "    '''\n",
        "    mask_rle: run-length as string formated (start length)\n",
        "    shape: (height,width) of array to return\n",
        "    Returns numpy array, 1 - mask, 0 - background\n",
        "\n",
        "    '''\n",
        "    s = mask_rle.split()\n",
        "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
        "    starts -= 1\n",
        "    ends = starts + lengths\n",
        "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
        "    for lo, hi in zip(starts, ends):\n",
        "        img[lo:hi] = 1\n",
        "    return img.reshape(shape, order='F')\n",
        "\n",
        "save_folder = r'/content/drive/MyDrive/test_label/'\n",
        "for idx, name in enumerate(tqdm(test_mask['name'].iloc[:])):\n",
        "    image = cv2.imread(name)\n",
        "    image = trfm(image)\n",
        "\n",
        "\n",
        "    # 将NumPy数组转换为张量\n",
        "    image_tensor = torch.tensor(image, dtype=torch.float32).unsqueeze(0).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        image = image.to(DEVICE)[None]\n",
        "        out=model(image)\n",
        "\n",
        "        score = model(image)[0][0]\n",
        "        score_sigmoid = score.sigmoid().cpu().numpy()\n",
        "        score_sigmoid = (score_sigmoid > 0.5).astype(np.uint8)\n",
        "        score_sigmoid = cv2.resize(score_sigmoid, (512, 512))\n",
        "        mask = cv2.morphologyEx(score_sigmoid, cv2.MORPH_CLOSE, kernel=np.ones((3, 3), np.uint8), iterations=1)\n",
        "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel=np.ones((3, 3), np.uint8),\n",
        "                                iterations=1)\n",
        "\n",
        "        image_name = os.path.basename(name)  # 提取图像文件名\n",
        "        save_path = os.path.join(save_folder, image_name.replace('.jpg', '_segmentation.png'))\n",
        "        plt.imsave(save_path, mask, cmap='gray')\n",
        "        # break\n",
        "    subm.append([name.split('/')[-1], rle_encode(score_sigmoid)])\n",
        "subm = pd.DataFrame(subm)\n",
        "subm.to_csv('./tmp.csv', index=None, header=None, sep='\\t')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PITTSzUv0cuN",
        "outputId": "c644a0b1-b422-4d26-b5fb-a5a9be6ce52b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "        Train | Valid\n",
            "Epoch |  Loss |  Loss | Time, m\n",
            "\n",
            "fold_idx: 4\n",
            "Epoch 00000: adjusting learning rate of group 0 to 1.0000e-04.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 797/3000 [05:59<16:02,  2.29it/s]"
          ]
        }
      ]
    }
  ]
}